{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5723bfa2",
   "metadata": {},
   "source": [
    "Import the following librairies and modules\n",
    "\n",
    "- `warnings`\n",
    "- `pandas`\n",
    "- `matplotlib.pyplot`\n",
    "- `seaborn`\n",
    "- `KMeans` from **sklearn**\n",
    "- `silhouette_score` from **sklearn**\n",
    "- `wordcloud` [Hint: wordcloud](https://amueller.github.io/word_cloud/auto_examples/single_word.html#sphx-glr-auto-examples-single-word-py)\n",
    "- `sentence_transformers` [Hint: sentece_transformers](https://sbert.net/)\n",
    "- `tqdm` [Hint : tqdm](https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1352c92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c330be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To suppress the warnings in the notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "EMBEDDER = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a99287",
   "metadata": {},
   "source": [
    "##### Step 1:\n",
    "\n",
    "- read the csv file `sentiment140_lemmatized.csv` and store in the variable `df`\n",
    "- set `header=0` and `index_col=0`.\n",
    "- display the first **5** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86114962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d219ebf",
   "metadata": {},
   "source": [
    "- Check if there are missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c34f3e7",
   "metadata": {},
   "source": [
    "##### Step 2:\n",
    "\n",
    "Here, we are transforming the texts into their numerical embeddings using the embedding model `distilbert-base-nli-mean-tokens` as called above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06d2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = EMBEDDER.encode(df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95f1e6",
   "metadata": {},
   "source": [
    "##### Step 3:\n",
    "\n",
    "- Do a **silhoutte_score** test for a range of (2,27,2). See the **kmeans** exercise or solution file.\n",
    "    - Find the number of clusters having high **silhoutte_score** except 2.\n",
    "    - Use `tqdm` in your for loop. It shows the progress bar. [Hint](https://stackoverflow.com/questions/43259717/progress-bar-for-a-for-loop-in-python-script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990e0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79f16516",
   "metadata": {},
   "source": [
    "##### Step 4:\n",
    "\n",
    "- For the selected number of clusters, do the **Kmeans** clustering.\n",
    "    - Fit the model on `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf48abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4b1a51",
   "metadata": {},
   "source": [
    "##### Step 5:\n",
    "\n",
    "- In the dataframe `df`, add another column `clusters` having the labels of your model as data in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b6e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7daa0f8f",
   "metadata": {},
   "source": [
    "##### Step 6:\n",
    "\n",
    "- Let us make the wordclouds of our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f5159bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(dataframe:pd.DataFrame, label:int):\n",
    "    \n",
    "    df_cluster = dataframe[dataframe[\"clusters\"]==label]\n",
    "    \n",
    "    all_words_joined_in_a_string = ' '.join([text for text in df_cluster[\"text\"].values])\n",
    "    \n",
    "    wordcloud = WordCloud(width=600, height=600, background_color ='white', min_font_size = 20).generate(all_words_joined_in_a_string) \n",
    "                    \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af01a9",
   "metadata": {},
   "source": [
    "- Iterate over a set of the labels of your model.\n",
    "    - display the label\n",
    "    - Select the data related to the label under iteration. \n",
    "        - Select the first **10** texts.\n",
    "        - make a list of these **10** texts.\n",
    "        - display the list\n",
    "    - using the `make_wordcloud`, make the wordclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd661c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1789b7",
   "metadata": {},
   "source": [
    "##### Step 7:\n",
    "\n",
    "- Looking at each printed list of texts and the wordcloud, what do you deduce about the theme of the cluster? Write your answer for each cluster (or atleast 4 clusters)below in a markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239385e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c8acf2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

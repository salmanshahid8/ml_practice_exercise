{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following librairies and modules\n",
    "\n",
    "- `re`\n",
    "- `nltk`\n",
    "- `warnings`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `matplotlib.pyplot`\n",
    "- `tqdm` [Hint : tqdm](https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/)\n",
    "- `TextBlob` [Hint : TextBlob](https://textblob.readthedocs.io/en/dev/index.html)\n",
    "- `stopwords` [Hint : stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)\n",
    "- `TfidfVectorizer`  [Hint : TfidfVectorizer](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- `train_test_split`\n",
    "- `ConfusionMatrixDisplay`, `f1_score`\n",
    "- `MultinomialNB`, `MLPClassifier`, `LinearSVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To suppress the warnings in the notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download the stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set of stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1:\n",
    "\n",
    "- read the csv file `sentiment140.csv` and store in the variable `df`\n",
    "- set `header=0` and `index_col=0`.\n",
    "- display the first **5** rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if there are missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2:\n",
    "\n",
    "Here, we are making functions to:\n",
    "- preprocess the text data to clean it\n",
    "- remove the stopwords from the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(input_text:str):\n",
    "    \n",
    "    input_text = input_text.lower()\n",
    "    input_text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",input_text).split())\n",
    "    input_text = input_text.replace(\" s \", \"'s \")\n",
    "    output_text = input_text.replace(\" t \", \"'t \")\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "def remove_stopword(input_text:str):\n",
    "    \n",
    "    output_text = ' '.join(word for word in input_text.split() if word not in STOPWORDS)\n",
    "    \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are applying the `text_processing` function on the **text** column of our dataframe **df** by using `progress_apply` and the famous `lambda` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"Preprocessing text\")\n",
    "df[\"text\"] = df[\"text\"].progress_apply(lambda sentence : text_processing(sentence))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like above, use the `remove_stopword` function to remove stopwords from the sentences in the dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: \n",
    "\n",
    "Using `TextBlob`, we are calculating the polarity of the sentences individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text:str):\n",
    "    \n",
    "    sentiment = None\n",
    "    text_pro = TextBlob(text)\n",
    "    polarity = text_pro.sentiment.polarity\n",
    "    \n",
    "    if polarity < 0:\n",
    "        sentiment = \"negative\"\n",
    "    elif polarity == 0:\n",
    "        sentiment = \"neutral\"\n",
    "    elif polarity > 0:\n",
    "        sentiment = \"positive\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like above, use the `get_sentiment` function to add another column `sentiment` in the dataframe `df`. This column should have the sentiment values as given in `if...elif` loop in the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4:\n",
    "\n",
    "- Split the data into input variables `X` and target variable `y`.\n",
    "- Here you have to identify the type of problem and target variable. Write your answers in a markdown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5:\n",
    "\n",
    "- Call the `TfidfVectorizer` method and store in a variable `vectorizer`.\n",
    "- **fit_transform** the `X_list`, whereas, `X_list` should be the `text` column of dataframe `df` transformed into a list. Store the result in variable `X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6:\n",
    "\n",
    "- Do the train_test_split with `test_size=0.20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7:\n",
    "\n",
    "- Call the three estimators that you imported and store them in separate variables.\n",
    "- **Fit** the data on these estimators.\n",
    "- Display their respective `ConfusionMatrixDisplay.from_estimator` for both train data and test data\n",
    "- Compare their **f1_score** and give a conclusion about which one is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 8:\n",
    "\n",
    "- Repeat steps from **1** to **7** (except step **3**) for the estimator you find the most suitable for the real world implementation data.\n",
    "    - The file name is `sentiment140_rwi.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 9:\n",
    "\n",
    "- Add a column in your `df_rwi` showing the predicted sentiments. By looking at first 10 rows, do you think that the model predicted well the sentiment of the texts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enedis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

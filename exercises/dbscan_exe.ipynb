{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following librairies and modules\n",
    "\n",
    "- `pickle`\n",
    "- `warnings`\n",
    "- `itertools`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `folium` => if it is not found in your base environment, run this command once in a cell `! pip install folium`\n",
    "- ``StandardScaler``    [StandardScaler](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "- `DBSCAN`  [DBSCAN](https://scikit-learn.org/dev/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "- `Silhoutte Score`     [Silhoutte score](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.silhouette_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To suppress the warnings in the notebook\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1:\n",
    "\n",
    "- read the csv file `weather_data.csv` and store in the variable `df`\n",
    "- keep only these columns : `Stn_Name` `Lat` `Long` `Tm` `Tx` `Tn`\n",
    "- display the first **5** rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2:\n",
    "- Check the missing values.\n",
    "    - If you find the missing values, drop the **rows** having atleast 1 missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- keep only these columns  `Lat` `Long` `Tm` `Tx` `Tn` and store in a new variable `X`,rather then `df`.\n",
    "- transform the dataframe `X` into **multidimensional array** using [nan_to_num](https://numpy.org/doc/2.0/reference/generated/numpy.nan_to_num.html)\n",
    "- **fit_transform** the **ndarray** `X` using **StandardScaler** and store in variable `X`\n",
    "- display the **ndarray** `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3:\n",
    "\n",
    "- Make the map of Canada using folium and store it in a variable `map_canada`. [Folium map](https://python-visualization.github.io/folium/latest/user_guide/map.html)\n",
    "    - Canada is situated between latitude `56` and longitude `-106`\n",
    "    - keep `zoom_start=4`. You can even play with **zoom_start** to see the difference.\n",
    "    \n",
    "- Now we would like to indicate the weather stations on this map. To do this:\n",
    "    - Iterate over the columns `Lat` and `Long` of your `df`. You need to `zip` both columns to keep one to one correspondance between latitude value and longitude value. [Hint](https://www.python-engineer.com/posts/zip-for-loop/)\n",
    "        - For each latitude/logitude pair, put a **red** dot on the `map_canada`. [Folium CircleMaker](https://python-visualization.github.io/folium/latest/user_guide/vector_layers/circle_and_circle_marker.html)\n",
    "        - Keep ``radius=1`` ``fill=True`` ``color='red'`` in the arguments\n",
    "\n",
    "- Display the output of variable `map_Canada`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4:\n",
    "\n",
    "To tune the hyperparameters of the `DBSCAN` model, we can either do hit and trial method and record the results, or we can use grid-search to find the optimum hyperparameters. Here we are choosing the later option.\n",
    "\n",
    "To do grid-search, first you have to make the combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a sequence between **0.01** and **1** using [linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) and store it in a variable `epsilon`. Keep `num=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make another sequence between **2** and **25** using [arange](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) and store it in a variable `min_samples`. Keep `step=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using [itertools](https://www.geeksforgeeks.org/python-itertools-product/), make a **list** of combinations of `epsilon` and `min_samples` and store it in a variable `combinations`\n",
    "- Show the count of combimations in the list `combinations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(combinations,X):\n",
    "    scores = []\n",
    "    \n",
    "    for i, (eps, num_samples) in enumerate(combinations):\n",
    "        \n",
    "        gs_model = DBSCAN(eps=eps, min_samples=num_samples)\n",
    "        gs_model.fit(X)\n",
    "        labels = gs_model.labels_\n",
    "\n",
    "        if (not list(set(labels)) == [-1]) and (len(list(set(labels))) > 2):\n",
    "\n",
    "            scr = silhouette_score(X, gs_model.labels_,metric=\"euclidean\",sample_size=1000,random_state=200)\n",
    "            scores.append(scr)\n",
    "            print(f\"at iteration {i}, silhoutte_score={scr}, we found number of clusters={len(list(set(labels)))}\")\n",
    "\n",
    "    best_index = np.argmax(scores)\n",
    "    best_parameter = combinations[best_index]\n",
    "\n",
    "    print(f\"\\nbest values are : eps={best_parameter[0]}, min_samples={best_parameter[1]}\")\n",
    "    \n",
    "    return best_parameter[0], best_parameter[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call the `gridSearch` method and find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5:\n",
    "\n",
    "Now that we have our best hyperparameter values, we can use them to make a **DBSCAN** model.\n",
    "- Call the `DBSCAN()` method, set the best hyperparameter values and store in a variable `model`\n",
    "- Fit the `model` on the **ndarray** `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the unique values of labels of model using `set` method. Display these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a new column `Labels` in the dataframe `df`.\n",
    "- Display the first **5** rows of dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {-1:'gray', 0:'red',1:'blue',2:'green',3:'yellow',4:'orange', 5:'pink',6:'purple'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 6:\n",
    "\n",
    "- Iterate over the columns `Lat`, `Long` and `Labels` using `zip` function.\n",
    "    - Copy and paste **label = folium.Popup('Cluster : '+str(lbl),parse_html=True)**\n",
    "    - Use `folium.CircleMaker` as you used before.\n",
    "        - `color=color_map[lbl]`\n",
    "        - `fill=True`\n",
    "        - `radius=1`\n",
    "        - `popup=label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 7:\n",
    "\n",
    "- Save the model as we always do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real World Use-Case:\n",
    "\n",
    "Now that you have trained a clustering model, let us test on real-world use-case to identify the relevant clusters.\n",
    "\n",
    "- read the csv file `weather_data_rwi.csv` and store in the variable `df_rwi`. keep only these columns : `Stn_Name` `Lat` `Long` `Tm` `Tx` `Tn`.\n",
    "- check the missing values. If you find the missing values, drop the **rows** having atleast 1 missing value.\n",
    "- keep only these columns  `Lat` `Long` `Tm` `Tx` `Tn` and store in a new variable `X`,rather then `df`.\n",
    "    - transform the dataframe `X` into **multidimensional array** using [nan_to_num](https://numpy.org/doc/2.0/reference/generated/numpy.nan_to_num.html)\n",
    "    - **fit_transform** the **ndarray** `X` using **StandardScaler** and store in variable `X`\n",
    "    - display the **ndarray** `X`\n",
    "- load the saved model and store it in variable `loaded_model`.\n",
    "- follow step 5 and step 6 to predict on the `loaded_model` and visualize it on `map_canada` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enedis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following packages and functions\n",
    "\n",
    "- random , warnings, numpy, pandas, matplotlib\n",
    "- tensorflow as tf\n",
    "- MinMaxScaler from ``sklearn``\n",
    "- list_physical_devices, Sequential, LSTM and Dense from `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a fixed random seed for reproducibility\n",
    "random.seed(42)  # For Python's built-in random module\n",
    "np.random.seed(42)  # For NumPy's random number generator\n",
    "tf.random.set_seed(42)  # For TensorFlow's random number generator\n",
    "\n",
    "# To suppress the warnings in the notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Checking if GPU is installed on PC. If not, the neural network model\n",
    "# will take many hours to train the model on CPU\n",
    "list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the data file **pgm_consumption.csv**\n",
    "    - Set the `datetime` column as index, while the datatype of each timestamp should NOT be str\n",
    "    - Sort the index\n",
    "    - Display the top 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keep only the data between the following dates using the `loc` function.\n",
    "    - start : **2005-01-01 00:00:00**\n",
    "    - end : **2017-12-31 23:59:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resample the data by `mean` from hourly data to daily data.\n",
    "- Display the top 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the bottom 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manually split the dataset into train subset and test subset using the `loc` function.\n",
    "    - The variable names of new subsets should be `train` and `test`\n",
    "    - The range of train subset should be between **2005-01-01 00:00:00** and **2016-12-31 23:59:00**\n",
    "    - Similarly, the range of test subset should be from **2017-01-01 00:00:00** to onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_and_y(dataframe:pd.DataFrame, lag:int, is_train=False) -> np.array:\n",
    "    \n",
    "    # Scaling the data between 0 and 1\n",
    "    dataframe = dataframe.values\n",
    "    scale = MinMaxScaler(feature_range=(0, 1))\n",
    "    data_array = scale.fit_transform(dataframe)\n",
    "    \n",
    "    # defining empty lists of X and y\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Range should be from the lag Values to END \n",
    "    for i in range(lag, data_array.shape[0]):\n",
    "        \n",
    "        # X_Train \n",
    "        X.append(data_array[i-lag:i])\n",
    "        \n",
    "        # y Would be t+lag Value based on past lag Values \n",
    "        y.append(data_array[i])\n",
    "\n",
    "    # Convert into Numpy Array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Shape should be Number of [Datapoints , Steps , 1 )\n",
    "    # we convert into 3-d Vector or #rd Dimesnsion\n",
    "    X = np.reshape(X, newshape=(X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    if bool(is_train):\n",
    "        return X, y, scale\n",
    "    else:\n",
    "        return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below, make a new variable `lag` having value equals to **30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, You should add lagging features of the `consumption` data.\n",
    "    - Earlier, you made the `lag=30`. This refers to lag features for 30 previous days.\n",
    "    - Using the user-defined function `get_X_and_y`, make the following subsets of earlier subsets.\n",
    "        - `X_train` and `y_train`. Be careful about the output variables of the function.\n",
    "        - `X_test` and `y_test`. Again, be careful about the output variables of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the shape of **X_train, y_train, X_test, y_test**.\n",
    "    - Do you see any anomaly in the shape of X_test and y_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a tensorflow model by sequentially adding the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the model on `X_train` and `y_train` and store/attribute in a variable `history`. Add the following arguments/inputs to the `fit` method.\n",
    "    - epochs = 50\n",
    "    - batch_size = 32\n",
    "    - validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    # Extract the training loss and validation loss\n",
    "    train_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    \n",
    "    # Plotting the training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(validation_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the losses. \n",
    "- In a markdown below\n",
    "    - Tell whether the model is well learning, underfitting or overfitting?\n",
    "    - Do you validate the model to be used on test subset? Justify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict on **X_test** and store it in a variable `y_predict_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the ``scale`` that you established above, `inverse_transform` the **y_test** and and **y_predict_test**\n",
    "    - You can store the results in same variables i.e. **y_test** and and **y_predict_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you display both, you see that they are n_dimensional arrays. We need them to be 1 dimensional arrays just like lists.\n",
    "    - Use the `flatten` function of numpy arrays to transform it into 1-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a dataframe of the two arrays above i.e. **y_test** and **y_predict_test**.\n",
    "- Plot the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the model in `.keras` format. See [New high-level .keras format](https://www.tensorflow.org/tutorials/keras/save_and_load#new_high-level_keras_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enedis_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
